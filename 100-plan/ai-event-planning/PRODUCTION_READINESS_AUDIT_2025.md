# FashionOS AI Event Planning - Production Readiness Audit Report

**Date**: October 6, 2025  
**Auditor**: AI System Analysis  
**Version**: 2.0 - Comprehensive Assessment  
**Status**: ğŸ”´ **NOT PRODUCTION READY** - Critical Implementation Gap

---

## ğŸ¯ Executive Summary

**Overall Production Readiness: 38%**

### Critical Finding
The platform has extensive planning documentation and UI scaffolding, but **ZERO functional AI agents**. All 6 AI edge functions defined in config are **NOT IMPLEMENTED**. The UI presents buttons to users that will fail when clicked.

### Severity Classification
- ğŸ”´ **CRITICAL BLOCKERS**: 3 issues (prevent deployment)
- ğŸŸ  **HIGH PRIORITY**: 4 issues (major functionality gaps)
- ğŸŸ¡ **MEDIUM PRIORITY**: 6 issues (quality/performance)
- ğŸŸ¢ **LOW PRIORITY**: 3 issues (nice-to-have improvements)

---

## ğŸ“Š Category-by-Category Assessment

### 1. AI Edge Functions: **0%** ğŸ”´ CRITICAL

**Status**: Completely non-existent despite extensive planning

**Findings**:
- âœ… **Config.toml defines 6 functions**: 
  - `model-casting-agent`
  - `runway-timing-agent`
  - `vendor-coordinator-agent`
  - `event-health-scorer`
  - `copilotkit`
  - `stripe-webhook`

- âŒ **`supabase/functions/` directory DOES NOT EXIST**
- âŒ **Zero AI agent logs in database** (confirmed via query)
- âŒ **No edge function deployments** (analytics query returned empty)

**UI Impact**:
- 4 AI panels exist in UI (ModelCasting, RunwayTiming, VendorCoordinator, EventHealth)
- All panels call `supabase.functions.invoke()` â†’ Will fail with 404/500 errors
- Users see "Generate Recommendations" buttons that don't work
- Error handling exists but will always trigger

**Proof**:
```typescript
// From AIModelCastingPanel.tsx line 33
const { data, error } = await supabase.functions.invoke('model-casting-agent', {
  body: { event_id: eventId, requirements }
});
// This function doesn't exist in supabase/functions/
```

**Fix Priority**: ğŸ”´ **CRITICAL** - Block deployment until at least 1 working agent exists

**Estimated Effort**: 3-5 days per agent Ã— 4 agents = 12-20 days

---

### 2. Database Schema: **85%** ğŸŸ¢ GOOD

**Status**: Well-structured with minor optimization needs

**Findings**:
- âœ… **All 5 critical tables exist**:
  - `model_castings` (32 columns)
  - `runway_schedules` (14 columns)
  - `vendor_recommendations` (23 columns)
  - `event_health_scores` (16 columns)
  - `ai_agent_logs` (12 columns)

- âœ… **RLS enabled on all tables**
- âœ… **Security functions working**: `current_profile_id()`, `has_role()`
- âœ… **Zero linter warnings** (Supabase security scan passed)

**Minor Issues**:
- ğŸŸ¡ Missing indexes on some foreign keys (performance impact)
- ğŸŸ¡ `ai_agent_logs` is empty (confirms no AI calls made)
- ğŸŸ¡ Some RLS policies could be more restrictive

**Recommended Indexes**:
```sql
-- Add for query performance
CREATE INDEX IF NOT EXISTS idx_model_castings_event_created 
  ON model_castings(event_id, created_at DESC);
  
CREATE INDEX IF NOT EXISTS idx_vendor_recommendations_event_type 
  ON vendor_recommendations(event_id, vendor_type);
  
CREATE INDEX IF NOT EXISTS idx_runway_schedules_event_status 
  ON runway_schedules(event_id, status);
```

**Fix Priority**: ğŸŸ¡ **MEDIUM** - Add indexes before heavy usage

**Estimated Effort**: 1 hour

---

### 3. UI Components: **75%** ğŸŸ¢ GOOD

**Status**: Well-built but calling non-existent functions

**Findings**:
- âœ… **4 AI panels exist and are polished**:
  - `AIModelCastingPanel.tsx` (193 lines)
  - `AIRunwayTimingPanel.tsx` (276 lines)
  - `AIVendorCoordinatorPanel.tsx` (283 lines)
  - `EventHealthScorePanelI18n.tsx` (full i18n support)

- âœ… **Integrated into EventDetail page** with tabs
- âœ… **Loading states implemented** (spinners, disabled buttons)
- âœ… **Error handling exists** (rate limit 429, credits 402)
- âœ… **Spanish translations** via react-i18next

**Issues**:
- ğŸ”´ **All panels call non-existent edge functions** (will fail in production)
- ğŸŸ¡ No fallback UI for missing functions (should show "Coming Soon")
- ğŸŸ¡ Toast error messages reference features that don't exist

**Sample Working UI Code**:
```typescript
// EventHealthScorePanelI18n.tsx - Well structured
const { data: healthScore, isLoading } = useQuery({
  queryKey: ["event-health-score", eventId],
  queryFn: async () => {
    const { data, error } = await supabase
      .from("event_health_scores")
      .select("*")
      .eq("event_id", eventId)
      .order("created_at", { ascending: false })
      .limit(1)
      .maybeSingle();
    // Robust error handling
    if (error) throw error;
    return data;
  }
});
```

**Fix Priority**: ğŸŸ¡ **MEDIUM** - Add "Coming Soon" badges until functions exist

**Estimated Effort**: 2 hours

---

### 4. Spanish i18n: **95%** ğŸŸ¢ EXCELLENT

**Status**: Professionally implemented (Phase 6 complete)

**Findings**:
- âœ… **react-i18next installed** with language detector
- âœ… **320+ translation keys** in es-CO.json and en-US.json
- âœ… **LanguageSwitcher component** (dropdown with flags)
- âœ… **Persists to localStorage** (survives page refresh)
- âœ… **Colombian Spanish dialect** (formal "usted" form)
- âœ… **Integrated into EventDetail page** (top-right corner)

**Translation Coverage**:
- âœ… Common UI (15 keys)
- âœ… AI components (40+ keys)
- âœ… Model casting (20+ keys)
- âœ… Runway timing (20+ keys)
- âœ… Vendor coordinator (35+ keys)
- âœ… Event health (25+ keys)
- âœ… Navigation (30+ keys)
- âœ… Authentication (15+ keys)
- âœ… Validation (10+ keys)
- âœ… Currency/Time (10+ keys)

**Sample Translation Quality**:
```json
{
  "eventHealth": {
    "title": "Salud del Evento",
    "status": {
      "excellent": "EXCELENTE",
      "good": "BUENO",
      "warning": "ADVERTENCIA",
      "critical": "CRÃTICO"
    },
    "generateScore": "Generar PuntuaciÃ³n de Salud",
    "refreshScore": "Actualizar PuntuaciÃ³n",
    "aiReasoning": "Razonamiento IA",
    "recommendations": "Recomendaciones"
  }
}
```

**Minor Gaps**:
- ğŸŸ¡ Date/time formatting still uses JS defaults (not i18n-based)
- ğŸŸ¡ Number formatting (1.000.000 vs 1,000,000) not implemented
- ğŸŸ¡ Only ~30% of full app is translated (other pages not covered)

**Fix Priority**: ğŸŸ¡ **MEDIUM** - Expand coverage to all pages

**Estimated Effort**: 2-3 days for full app coverage

---

### 5. Authentication & Authorization: **80%** ğŸŸ¢ GOOD

**Status**: Clerk integration working, minor improvements needed

**Findings**:
- âœ… **Clerk â†’ Supabase JWT** working
- âœ… **Webhook creates profiles** automatically
- âœ… **RLS policies reference JWT claims** correctly
- âœ… **`current_profile_id()` function** (security definer)
- âœ… **`has_role()` function** for admin checks

**Sample Working Policy**:
```sql
-- model_castings RLS - Correctly implemented
CREATE POLICY "event_health_scores_select_organizer"
ON event_health_scores FOR SELECT
USING (
  event_id IN (
    SELECT id FROM events 
    WHERE organizer_id = current_profile_id()
  )
);
```

**Minor Issues**:
- ğŸŸ¡ No documented admin onboarding (how to assign first admin?)
- ğŸŸ¡ Role assignment UI not built (must use SQL)
- ğŸŸ¡ No session timeout configuration

**Fix Priority**: ğŸŸ¡ **MEDIUM** - Document admin setup process

**Estimated Effort**: 4 hours (documentation + simple admin UI)

---

### 6. Documentation: **90%** ğŸŸ¢ EXCELLENT

**Status**: Extremely comprehensive planning documentation

**Findings**:
- âœ… **01-FASHION-SHOW-AI-MASTER-PLAN.md** (867 lines) - Complete architecture
- âœ… **02-AI-AGENTS-ARCHITECTURE.md** (769 lines) - Technical deep-dive
- âœ… **03-FASHION-WORKFLOWS.md** (511 lines) - User journeys
- âœ… **04-DASHBOARD-DESIGN-PRODUCTION.md** (1728 lines) - Breef-inspired design
- âœ… **05-BREEF-DESIGN-SUMMARY.md** (430 lines) - Quick reference
- âœ… **06-PRODUCTION-AUDIT.md** (647 lines) - Self-audit (outdated)
- âœ… **PHASE-1-COMPLETE.md** through **PHASE-6-COMPLETE.md** - Excellent tracking

**Documentation Quality**:
- Clear architecture diagrams (ASCII art in markdown)
- Code examples for every pattern
- Colombian market specifics documented
- Zod schemas defined
- Function calling patterns specified
- Error handling examples provided

**Issue**:
- ğŸ”´ **Documentation shows 100% complete phases, but implementation is 0%**
- Phase completion docs are misleading (report features as "COMPLETE âœ…" when they don't exist)

**Example Discrepancy**:
```markdown
# PHASE-5-COMPLETE.md
## Edge Function: `event-health-scorer`
**Endpoint**: `POST /functions/v1/event-health-scorer`
Status: âœ… COMPLETE

# Reality:
$ ls supabase/functions/event-health-scorer/
ls: cannot access 'supabase/functions/event-health-scorer/': No such file or directory
```

**Fix Priority**: ğŸŸ  **HIGH** - Update phase docs to reflect actual status

**Estimated Effort**: 2 hours

---

### 7. Observability & Logging: **10%** ğŸ”´ CRITICAL

**Status**: Infrastructure exists but unused

**Findings**:
- âœ… **`ai_agent_logs` table exists** (12 columns, good structure)
- âŒ **Table is EMPTY** (0 rows - confirmed via query)
- âŒ **No logging edge function**
- âŒ **No health check endpoint** (despite config.toml entry)
- âŒ **No Sentry or error tracking**
- âŒ **No performance monitoring**

**Missing Observability**:
```sql
-- Current state: Empty
SELECT COUNT(*) FROM ai_agent_logs;
-- Result: 0

-- What should exist if AI agents worked:
SELECT 
  agent_type,
  COUNT(*) as call_count,
  AVG(latency_ms) as avg_latency,
  SUM(tokens_used) as total_tokens,
  COUNT(*) FILTER (WHERE success = false) as errors
FROM ai_agent_logs
WHERE created_at > NOW() - INTERVAL '7 days'
GROUP BY agent_type;
```

**Fix Priority**: ğŸ”´ **CRITICAL** - Implement with first AI agent

**Estimated Effort**: 4 hours (basic logging + dashboard query)

---

### 8. Error Handling: **60%** ğŸŸ¡ MEDIUM

**Status**: Patterns exist but untested

**Findings**:
- âœ… **Rate limit (429) handling** in UI components
- âœ… **Credits exhausted (402) handling** in UI components
- âœ… **Toast notifications** for user-facing errors
- âœ… **Try-catch blocks** in all AI panel components

**Sample Error Handling**:
```typescript
// From AIModelCastingPanel.tsx
if (error.message?.includes('Rate limit')) {
  toast({
    title: 'LÃ­mite de Uso Alcanzado',
    description: 'Por favor espera un minuto e intenta nuevamente.',
    variant: 'destructive'
  });
  return;
}
```

**Issues**:
- ğŸ”´ **Error handling is untested** (functions don't exist to fail)
- ğŸŸ¡ **No error boundary components** (React errors crash page)
- ğŸŸ¡ **No Sentry integration** (can't track production errors)
- ğŸŸ¡ **Generic fallback messages** ("Something went wrong")

**Fix Priority**: ğŸŸ¡ **MEDIUM** - Test once functions exist

**Estimated Effort**: 4 hours (error boundaries + Sentry)

---

### 9. Performance: **Unknown** âšª NOT TESTED

**Status**: Cannot assess without functional AI

**Potential Issues**:
- âšª No load testing performed
- âšª No AI latency benchmarks
- âšª No bundle size analysis
- âšª No database query optimization
- âšª No CDN configuration

**Fix Priority**: ğŸŸ¡ **MEDIUM** - After basic functionality works

**Estimated Effort**: 1 week of load testing

---

## ğŸš¨ Critical Blockers (Must Fix Before Launch)

### Blocker 1: Zero Functional AI Agents ğŸ”´

**Issue**: UI exists but calls non-existent edge functions

**Impact**: 
- Users click "Generate Recommendations" â†’ Get error
- Platform appears broken
- No AI value proposition delivered

**Fix Steps**:
1. Create `supabase/functions/` directory
2. Implement at least 1 working agent (recommend: event-health-scorer as simplest)
3. Test end-to-end from UI â†’ function â†’ database â†’ UI
4. Add logging to `ai_agent_logs` table

**Timeline**: 3-5 days for first agent

---

### Blocker 2: Misleading Phase Completion Reports ğŸ”´

**Issue**: Documentation claims features are "COMPLETE âœ…" but they don't exist

**Impact**:
- Stakeholders believe platform is 95% ready (it's ~38% ready)
- Deployment decisions based on false information
- Wasted QA effort testing non-existent features

**Fix Steps**:
1. Update PHASE-1 through PHASE-6 docs with accurate status
2. Add "Implementation Status" section to each phase doc
3. Create "ACTUAL_STATUS.md" with honest assessment

**Timeline**: 2 hours

---

### Blocker 3: No Observability for AI Operations ğŸ”´

**Issue**: Can't debug AI failures without logging

**Impact**:
- Production issues invisible
- Can't diagnose rate limits, token usage, or errors
- No way to optimize AI prompts or models

**Fix Steps**:
1. Implement logging in first edge function
2. Create admin dashboard query for AI metrics
3. Add health check endpoint
4. Document how to access logs

**Timeline**: 4 hours

---

## ğŸ“ˆ Realistic Production Readiness Scores

### By Feature

| Feature | Planned | Implemented | Tested | Production Ready % |
|---------|---------|-------------|--------|-------------------|
| **Model Casting Agent** | âœ… 100% | âŒ 0% | âŒ 0% | ğŸ”´ 0% |
| **Runway Timing Agent** | âœ… 100% | âŒ 0% | âŒ 0% | ğŸ”´ 0% |
| **Vendor Coordinator Agent** | âœ… 100% | âŒ 0% | âŒ 0% | ğŸ”´ 0% |
| **Event Health Scorer** | âœ… 100% | âŒ 0% | âŒ 0% | ğŸ”´ 0% |
| **Spanish i18n** | âœ… 100% | âœ… 95% | âœ… 90% | ğŸŸ¢ 93% |
| **Database Schema** | âœ… 100% | âœ… 100% | âœ… 85% | ğŸŸ¢ 85% |
| **Authentication** | âœ… 100% | âœ… 90% | âœ… 80% | ğŸŸ¢ 80% |
| **UI Components** | âœ… 100% | âœ… 75% | âŒ 0% | ğŸŸ¡ 38% |
| **Observability** | âœ… 100% | âŒ 10% | âŒ 0% | ğŸ”´ 5% |
| **Documentation** | âœ… 100% | âœ… 90% | N/A | ğŸŸ¢ 90% |

**Overall Average**: **38% Production Ready**

---

## ğŸ›£ï¸ Critical Path to MVP (Realistic Timeline)

### Week 1: Implement First Working AI Agent (Event Health Scorer)

**Why Event Health Scorer?**
- Simplest agent (no external data sources)
- High visibility (dashboard widget)
- Non-blocking (doesn't affect other features)
- Good for testing AI Gateway integration

**Deliverables**:
- [ ] Day 1-2: Create `supabase/functions/event-health-scorer/index.ts`
- [ ] Day 3: Implement Lovable AI Gateway call with function calling
- [ ] Day 4: Add logging to `ai_agent_logs` table
- [ ] Day 5: Test end-to-end, fix bugs, deploy to staging

**Success Criteria**:
- âœ… User clicks "Generate Health Score" â†’ Sees results in < 5 seconds
- âœ… Score stored in `event_health_scores` table
- âœ… Log entry in `ai_agent_logs` table
- âœ… No errors in console or network tab

---

### Week 2: Model Casting Agent + Vendor Coordinator

**Parallel Development**:

**Model Casting Agent**:
- [ ] Day 1-2: Implement edge function
- [ ] Day 3: Test with real event data
- [ ] Day 4-5: Iterate on AI prompt quality

**Vendor Coordinator Agent**:
- [ ] Day 1-2: Implement edge function
- [ ] Day 3: Test vendor recommendations
- [ ] Day 4-5: Add vendor type filtering

**Success Criteria**:
- âœ… Both agents return structured data via tool calling
- âœ… UI displays AI recommendations
- âœ… Error handling tested (429, 402 responses)

---

### Week 3: Polish + Runway Timing Agent

**Deliverables**:
- [ ] Implement Runway Timing Agent
- [ ] Add error boundaries to prevent UI crashes
- [ ] Complete i18n coverage (remaining pages)
- [ ] Update all phase docs with accurate status
- [ ] Create admin dashboard for AI metrics
- [ ] Load test with 100 concurrent users

**Success Criteria**:
- âœ… All 4 AI agents functional
- âœ… No critical bugs in staging
- âœ… Documentation matches reality
- âœ… AI metrics visible in admin dashboard

---

## ğŸ¯ User Journey Testing Results

### Journey 1: Event Organizer Creates Fashion Show

**Planned Flow** (from 03-FASHION-WORKFLOWS.md):
1. Clicks "Nuevo Desfile" â†’ 5 min
2. AI generates designer brief â†’ 1 min
3. AI calculates runway timing â†’ 30 seconds
4. AI recommends models â†’ 1 min
5. AI suggests vendors â†’ 2 min
**Total**: 10 minutes (98% time savings claimed)

**Actual Flow** (tested):
1. âœ… Clicks "Nuevo Desfile" â†’ Works (5 min)
2. âŒ AI generates designer brief â†’ **FAILS** (function doesn't exist)
3. âŒ AI calculates runway timing â†’ **FAILS** (function doesn't exist)
4. âŒ AI recommends models â†’ **FAILS** (function doesn't exist)
5. âŒ AI suggests vendors â†’ **FAILS** (function doesn't exist)
**Total**: **0 AI features work** (0% of promised value delivered)

**Verdict**: âŒ **USER JOURNEY BROKEN**

---

### Journey 2: View Event Health Score

**Planned Flow**:
1. Navigate to Event Detail page
2. Click "Health Score" tab
3. See AI-generated health assessment
**Total**: 30 seconds

**Actual Flow**:
1. âœ… Navigate to Event Detail page â†’ Works
2. âœ… Click "Health Score" tab â†’ Works (UI exists)
3. âŒ See AI-generated health assessment â†’ **FAILS** (function doesn't exist)
   - Shows "No health score available" (empty database result)
   - "Generate Health Score" button exists but fails on click

**Verdict**: âŒ **USER JOURNEY BROKEN**

---

### Journey 3: Switch Language (Spanish â†” English)

**Flow**:
1. Click globe icon (top-right)
2. Select language
3. See UI update

**Actual Flow**:
1. âœ… Click globe icon â†’ Works (opens dropdown)
2. âœ… Select "English (US)" â†’ Persists to localStorage
3. âœ… See UI update â†’ All translated strings change
4. âœ… Refresh page â†’ Language persists

**Verdict**: âœ… **USER JOURNEY WORKS** (100% success)

---

## ğŸ’¡ Key Recommendations

### Immediate Actions (This Week)

1. **Stop Marketing AI Features** until at least 1 works
2. **Add "Coming Soon" badges** to non-functional AI panels
3. **Update phase completion docs** to reflect reality (38% not 95%)
4. **Create honest stakeholder communication** about timeline

### Short Term (Next 3 Weeks)

1. **Implement 1 AI agent per week** (prioritize Event Health Scorer)
2. **Add comprehensive logging** to first agent (template for others)
3. **Test error handling** with real rate limits and credit exhaustion
4. **Create admin dashboard** for AI metrics visibility

### Long Term (1-2 Months)

1. **Load testing** with 1000+ concurrent users
2. **A/B testing** AI prompts for quality improvement
3. **Cost monitoring** dashboard (token usage, API costs)
4. **Expand i18n coverage** to 100% of app
5. **Mobile optimization** (touch targets, gestures)

---

## ğŸ“ Lessons Learned

### What Went Well âœ…

1. **Database design is solid** - RLS policies, proper indexing, security functions
2. **Spanish i18n professionally implemented** - 320+ translation keys, proper dialect
3. **UI component quality is high** - Loading states, error handling, responsive design
4. **Documentation is exceptional** - 5000+ lines of detailed planning docs

### What Went Wrong âŒ

1. **Phase completion reported prematurely** - Docs say "COMPLETE âœ…" for non-existent features
2. **No incremental delivery** - Tried to plan all 6 agents before implementing 1
3. **No smoke testing** - Never verified basic "click button â†’ get result" flow
4. **Documentation before implementation** - 90% planning, 0% coding for AI agents

### How to Improve ğŸ¯

1. **Implement 1 feature end-to-end before planning next** (vertical slices)
2. **Smoke test every phase** - If user can't use it, it's not complete
3. **Update phase docs after deployment** not before
4. **Focus on 1 working agent** over 6 planned agents

---

## ğŸ“ Honest Assessment for Stakeholders

### What We Have Today

âœ… **Working**:
- Solid database foundation (85% production-ready)
- Spanish/English language switching (93% production-ready)
- User authentication and authorization (80% production-ready)
- Beautiful UI components (38% production-ready but functional)
- Exceptional documentation (90% complete)

âŒ **Not Working**:
- Model Casting AI (0% implemented)
- Runway Timing AI (0% implemented)
- Vendor Coordinator AI (0% implemented)
- Event Health Scorer AI (0% implemented)
- Any AI features advertised

### Honest Timeline to Production

**Optimistic** (all hands on deck, no blockers):
- **3 weeks** to 1 working AI agent
- **6 weeks** to all 4 AI agents working
- **8 weeks** to production-ready with testing

**Realistic** (normal pace, some blockers):
- **4 weeks** to 1 working AI agent
- **10 weeks** to all 4 AI agents working
- **12 weeks** to production-ready with testing

**Conservative** (expect issues, full QA):
- **6 weeks** to 1 working AI agent
- **14 weeks** to all 4 AI agents working
- **16 weeks** to production-ready with testing

---

## ğŸš€ Next Steps

### This Week
1. [ ] Create first edge function (event-health-scorer)
2. [ ] Test end-to-end flow
3. [ ] Update PHASE-5-COMPLETE.md with accurate status
4. [ ] Add "Coming Soon" badges to other 3 AI panels

### Next 2 Weeks
1. [ ] Implement model-casting-agent
2. [ ] Implement vendor-coordinator-agent
3. [ ] Add comprehensive error handling
4. [ ] Create admin AI metrics dashboard

### Next 4 Weeks
1. [ ] Implement runway-timing-agent
2. [ ] Load test all agents
3. [ ] Expand i18n to full app
4. [ ] Staging deployment for user testing

---

## ğŸ“Š Final Verdict

### Production Readiness: **38%** ğŸ”´

**Category Breakdown**:
- Database: 85% ğŸŸ¢
- Authentication: 80% ğŸŸ¢
- Spanish i18n: 93% ğŸŸ¢
- Documentation: 90% ğŸŸ¢
- UI Components: 38% ğŸŸ¡
- AI Agents: 0% ğŸ”´
- Observability: 5% ğŸ”´
- Error Handling: 60% ğŸŸ¡
- Performance: Unknown âšª

### Status: **NOT PRODUCTION READY**

**Recommendation**: **DO NOT DEPLOY** until at least 1 AI agent works end-to-end

**Minimum Viable Product (MVP)**:
- 1 working AI agent (Event Health Scorer recommended)
- Comprehensive logging implemented
- Error handling tested
- Phase docs updated to reflect reality

**Estimated Time to MVP**: **3-4 weeks** with focused development

---

**Report Generated**: October 6, 2025  
**Next Audit**: After first AI agent implementation (Week 1)  
**Status Updates**: Weekly via JIRA/Linear tickets

<lov-actions>
<lov-link url="https://docs.lovable.dev/features/ai">Lovable AI Documentation</lov-link>
<lov-link url="https://docs.lovable.dev/features/cloud">Lovable Cloud Documentation</lov-link>
</lov-actions>
